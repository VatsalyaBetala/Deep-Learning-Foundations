# **Deep Learning Foundations with Reference Materials**

## **Overview**

This repository contains a comprehensive collection of foundational deep-learning programming assignments, along with extensive reference materials. Each module is designed to provide a strong understanding of deep learning concepts, starting from the basics of mathematics to implementing deep learning models using PyTorch.

## **Table of Contents**
1. [Background Mathematics](#background-mathematics)
2. [Supervised Learning](#supervised-learning)
3. [Shallow Neural Networks](#shallow-neural-networks)
4. [Deep Neural Networks](#deep-neural-networks)
5. [Loss Functions](#loss-functions)
6. [Gradient Descent](#gradient-descent)
7. [Backpropagation](#backpropagation)
8. [PyTorch](#pytorch)

## **Getting Started**

### **Prerequisites**
- Python 3.x
- Jupyter Notebook
- Necessary Python libraries: numpy, pandas, matplotlib, PyTorch, etc.

You can install the required libraries using `pip`:

```bash
pip install -r requirements.txt
```

### **Cloning the Repository**

```bash
git clone https://github.com/VatsalyaBetala/Deep-Learning-Foundations.git
cd Deep-Learning-Foundations
```

### **Running the Notebooks**

Navigate to the desired module and open the Jupyter Notebook in the `ChapXX` folder:

```bash
jupyter notebook 01-Background-Mathematics/Chap01/your_notebook.ipynb
```

## **Modules Overview**

### **1. Background Mathematics**
This module covers the essential mathematical foundations required for deep learning. Topics include linear algebra, probability theory, and calculus.

- **Reading Materials:** Reference PDFs for linear algebra, probability, and other mathematical tools.
- **Programming Assignment:** Implement fundamental mathematical operations and understand their applications in deep learning.

### **2. Supervised Learning**
This module introduces the concept of supervised learning, where a model is trained on labeled data to make predictions.

- **Reading Materials:** PDFs explaining the theory and methods behind supervised learning.
- **Programming Assignment:** Develop basic supervised learning models and evaluate their performance.

### **3. Shallow Neural Networks**
Explore the basics of neural networks with a focus on shallow architectures.

- **Reading Materials:** Introductory PDFs on neural networks and their components.
- **Programming Assignment:** Build and train shallow neural networks.

### **4. Deep Neural Networks**
Delve into deep learning with multilayer neural networks, exploring more complex architectures.

- **Reading Materials:** In-depth PDFs on deep neural network structures.
- **Programming Assignment:** Implement and train deep neural networks.

### **5. Loss Functions**
Understand the different types of loss functions used in training neural networks.

- **Reading Materials:** Detailed explanations of various loss functions.
- **Programming Assignment:** Experiment with different loss functions and observe their effects on model training.

### **6. Gradient Descent**
Learn the mechanics of gradient descent, a fundamental optimization algorithm used in training models.

- **Reading Materials:** Theoretical PDFs on gradient descent and its variants.
- **Programming Assignment:** Implement gradient descent and explore its application in training models.

### **7. Backpropagation**
Master backpropagation, the key algorithm for training deep neural networks.

- **Reading Materials:** Comprehensive guide on the backpropagation algorithm.
- **Programming Assignment:** Implement backpropagation to optimize deep learning models.

### **8. PyTorch**
Get hands-on with PyTorch, one of the most popular deep learning frameworks.

- **Reading Materials:** Introductory PDFs to PyTorch and its functionalities.
- **Programming Assignment:** Implement deep learning models using PyTorch.

## **Contribution**

Contributions are welcome! If you have suggestions or improvements, feel free to fork the repository and submit a pull request.

## **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
